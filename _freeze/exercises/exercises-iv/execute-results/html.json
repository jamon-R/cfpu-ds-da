{
  "hash": "099f12a2a45d5b0109b257be9cea526e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercises IV\"\nsubtitle: \"Data Science and Data Analytics\"\nauthor: \"Julian Amon, PhD\"\ndate: \"April 30, 2025\"\ndate-format: long\nformat: html\nhighlight-style: arrow\nexecute: \n  warning: false\n  echo: false\n  eval: false\n  fig-height: 4\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n# The Data Science Workflow -- Model\n\n\n\n\n\n\n\n\n\n1.  The `ISLR2` package contains the `Boston` data set, which records `medv` (median house value) for 506 suburbs of Boston. We will seek to predict `medv` using 12 predictors such as `rm` (average number of rooms per house), `age` (proportion of owner-occupied units built prior to 1940) and `lstat` (percent of households with low socio-economic status).\n    a. Install and load the `ISLR2` package. Investigate the description of all variables in the `Boston` data set via `?Boston`.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    b. We will first do a random train-test split. Using the function `sample`, randomly choose 405 (i.e. approximately 80%) of the observations and assign them to a new `data.frame` called `train`. Assign all others to a `data.frame` called `test`.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    c. Using the training data set, estimate a simple linear regression model with `medv` as the response and `lstat` as the predictor. Inspect the created `lm` object using `summary` and interpret regression coefficients, their statistical significance and the $R^2$ statistic. Furthermore determine a 95%-confidence interval for the slope coefficient $\\beta_1$.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    d. Visualize the simple linear regression model you just fitted on the training data using a scatter plot. Hint: simply use `geom_smooth` with the method equal to `lm` and `se` set to `FALSE` to add the regression line into the scatter plot. Does the linear fit appear appropriate for the data at hand?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    e. Now, estimate a new model that uses the logarithm of `lstat` as an explanatory variable. Inspect its $R^2$ and compare to the one of the simple model that is linear in `lstat`. Visualize the corresponding regression line in another scatter plot. Hint: for the visualization of the non-linear regression line, use `geom_function`. This requires you to specify a function to be drawn into the scatter plot, for which you can use `predict`.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    f. We now want to compare the performance of different linear regression models using 10-fold cross validation. For this, first assign each **training** observation randomly to a fold between 1 and 10. Next, using these folds, determine the test MSE for each of the following linear regression models.\n        - M1: `medv ~ lstat`\n        - M2: `medv ~ log(lstat)`\n        - M3: `medv ~ log(lstat) + crim`\n        - M4: `medv ~ log(lstat) + crim + dis`\n        - M5: `medv ~ log(lstat) + dis + rm`\n        - M6: `medv ~ log(lstat) + dis + ptratio`\n        - M7: `medv ~ lstat + dis + ptratio + crim + nox`\n        - M8: `medv ~ log(lstat) + dis + ptratio + crim + nox`\n    \n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    g. Which of the models investigated in f. gives the lowest test MSE? Fit the corresponding model to the entire training data and investigate the model more deeply using `summary`.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    h. Using your cross-validation setup from f., compare the test MSE performance of the best-performing linear regression model now to the performance of KNN regression models that uses the same variables, i.e. `lstat`, `dis`, `ptratio`, `crim` and `nox`. Let $K$ vary between 2 and 10 and only compare the best-performing KNN approach to model M8. Is the non-parametric approach able to outperform the parametric one? \n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    i. Using all variables available in the data set, can you find an even better model? Fit your model, the model M8 and the KNN regression model with $K = 5$ from before on the entire `train` data set. Using these fits, compare the performance of the three models on the initial hold-out `test` data set from b. Which of the three approaches has the lowest MSE on that data set?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    j. Now, fit a regression tree that uses predictors `lstat`, `dis`, `ptratio`, `crim`, `nox`, `rm`, `tax` and `rad` to the entire training data. Make sure to set the complexity parameter `cp` to zero in the fitting process. Visualize the resulting tree using corresponding functionality from the `rpart.plot` package.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    k. Using the created `rpart` object, determine the optimal complexity parameter `cp` and create an optimally pruned tree. Finally, use both the unpruned and the optimally pruned tree to predict the response in the initial hold-out `test` data set from b. How do their MSEs compare to the models investigated in i.? Hint: Prediction with decision trees from `rpart` works just like it does for linear regression, so that you can use the `predict` function.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n\n2.  The `ISLR2` package also contains the `Default` data set, which contains information on ten thousand credit card customers. More specifically, the `data.frame` holds the following four variables: `default` (a factor with levels `No` and `Yes` indicating whether the customer defaulted on their debt), `student` (a factor indicating whether the customer is a student), `balance` (average outstanding balance at the end of the month), `income` (income of the customer in USD).\n    a. Start by appropriately visualizing the relationship between `default` (as the response) and each of the other three variables (as the predictors). Also create a scatter plot of `balance` against `income`, where the default cases are highlighted via colour and shape.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    b. Since the data set is quite big ($n = 10000$), we can afford to again set some observations aside as a test set for final evaluation. Using the function `sample`, randomly assign 90% of the observations to a new `data.frame` called `train` and assign all others to a `data.frame` called `test`.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    c. Write a function called `binary_class_metrics` that takes two `factor` arguments `y_pred` and `y_true`, both with two levels. The first represents the predicted classes and the second represents the true classes. The function is then supposed to return a named vector holding the `accuracy`, `recall`, `precision` and `f1` score of the binary classification of `y_true` using `y_pred`. Test your function for the case where the predictions are `1,1,1,0,0,0` and the truth is `1,1,0,1,1,0`. Hint: first compute the confusion matrix by using the function `table` and then compute the four metrics from that table.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    d. On the entire training data, estimate a logistic regression model for the `default` variable, using the other three variables as predictors. Inspect the model and interpret the coefficients. Which of them are significantly different from zero at the 5% significance level?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    e. Employing your function `binary_class_metrics` from earlier, investigate the **training set** performance of using the logistic regression model from d. as a classifier. Interpret the values of accuracy, recall and precision. Hint: with the `fitted` function, you can get the estimated default probabilities from your `glm` object. Be careful to set the factor levels to `No` and `Yes` to comply with the `default` `factor` in the training data.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    f. In the `Default` data set, we have one categorical predictor, namely whether the customer is a student or not. While logistic regression was easily able to handle that, this is more difficult for KNN classification, as one must decide how to measure distance in a feature space that combines categorical and numerical features. As we have a lot of data, we will follow a simple approach: fitting a separate KNN classifier for students and non-students, both with the same value for $K$. Use 10-fold cross validation on the training data to find the value for $K$ that maximizes the F1 score. Hint: in every iteration over the 10 folds, fit and predict the students and non-students separately using the two numeric features as predictors. Remember to scale the numeric features in every iteration.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    g. Next, fit a classification tree for `default` using the other three variables as predictors on the entire training data. Make sure to set the complexity parameter `cp` to zero in the fitting process. Visualize the resulting tree using corresponding functionality from the `rpart.plot` package.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    h. Using the fitted classification tree from g., determine the optimal complexity parameter `cp` and fit and visualize the optimally pruned classification tree.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    i. Finally, use the logistic regression model from d., the combined KNN classifier with optimal $K$ from f., the full classification tree from g. and the pruned classification tree from h. to predict the test observations in the initial hold-out sample from b. Feed the predictions of each into your function `binary_class_metrics` to evaluate their test set performances. Beyond just the metrics, consider the business implications of the different types of errors each model makes:\n        - False Positive (Predicting default when the customer will not): What are the potential costs to the credit card company?\n        - False Negative (Predicting no default when the customer will default): What are the potential costs to the credit card company?\n        - Based on these costs and the performance metrics, which model do you think the credit card company might prefer and why? Present the performance metrics in a table and follow it with your discussion.\n\n\n\n    \n\n\n\n3.  In the course materials, you should find the `advertising` data set discussed extensively in the lecture. Using 5-fold cross validation, we compared the performance of a linear regression and a KNN regression in class. A linear regression using all three advertising budgets as predictors had an estimated test MSE of 3.06, while a KNN regression with the same predictors and $K=2$, even had an estimated test MSE of 1.94. The goal is now to additionally examine the performance of a regression tree on that data set.\n    a. We will start with quite an **advanced** exercise that manually determines the first split in the tree. This is meant to build deeper understanding of what goes on behind the scenes of `rpart`, but is not strictly necessary, so you can skip ahead to c. if you wish to. The goal here is to write a function that takes two arguments: a vector of training observations of a quantitative feature and a vector of training observations of a quantitative response. The function should return the optimal split point $s$ and the resulting $RSS$ for that variable. Hint: first determine all possible split points of the predictor. Then cycle through the split points, at each point determining the left $RSS$, the right $RSS$ and then the sum. Save the split points and total $RSS$ in a matrix and return the row of the matrix for which the total $RSS$ is minimized. You may want to write a simple helper function to compute $RSS$.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    b. Now, import the advertising data set and select only the columns 3 to 6 (we do not need the rest). Use your function from a. to determine the optimal split for `social_media`, for `radio` and for `newspaper`, when using `sales` as a response variable. Which of those three predictors and split points is able to generate the lowest $RSS$? This will be our first split.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    c. If you have not done it so far, import the advertising data set and select only the columns 3 to 6 (we do not need the rest). Employ the `rpart` package to fit a regression tree for `sales`, using the other three variables as predictors and setting the complexity parameter `cp` to zero for the fitting process. Visualize the resulting tree. If you did exercises a. and b., compare the first split (at the very top) to the one you determined in exercise b. Did you come to the same result as the package?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    d. Using the fitted regression tree from c., determine the optimal complexity parameter `cp` and fit and visualize the optimally pruned regression tree for this data set.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    e. Finally, determine the test MSE of the optimally pruned tree in 5-fold cross validation. To do this, simply set the complexity parameter `cp` to the optimal value you found in d. already during fitting in each loop cycle of the cross validation. How does the performance of the optimally pruned regression tree compare to the linear regression and KNN model from the lecture?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n4.  We already know the `penguins` data set of the `palmerpenguins` package from the visualization part of this course. We will now try to build classification models for determining the species of penguin based on certain physical characteristics.\n    a. Load the data set and create a relative frequency table of the different penguin species in the entire data set. What is a crucial difference of this classification task compared to the previous one on defaults of credit card customers in exercise 2.?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    b. In the usual way, perform a random 80-20 train-test split. Make sure to remove any NA's in the data set before you do so.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    c. Out of the classification methods that we have learned, the ones that can easily be applied to multi-class classification problems are KNN classification and decision trees. We will start with the former: run a 5-fold cross-validation experiment to determine the accuracy-maximizing value of $K$ for two different KNN classifiers: one that only uses predictors `bill_length_mm` and `bill_depth_mm` and one that **additionally** uses predictors `flipper_length_mm` and `body_mass_g` to predict `species`. Make sure you scale the predictors in every iteration over the 5 folds. Hint: it might be helpful to write a little helper function that -- given a vector of class predictions and a vector of true classes -- computes the accuracy, i.e. the proportion of cases, where predicted class is equal to true class.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    d. Now, we will look at a classification tree for this data set. Fit a full classification tree for `species` based on predictors `bill_length_mm`, `bill_depth_mm`, `flipper_length_mm` and `body_mass_g` to the training data in the same way you would normally do for a binary classification problem. Determine the optimal complexity parameter `cp` and use it to also fit an optimally pruned tree. Visualize the outcome. What do you notice about the visualized tree compared to the binary classification case?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    e. Use the best-performing KNN model from c. as well as both the full and the optimally pruned tree from d. to predict the species of the penguins in the hold-out test data you created in b. Which of the three models gives the highest test accuracy in predicting the penguin species?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n5.  The Seeds data set (obtainable from [here](https://archive.ics.uci.edu/dataset/236/seeds)) contains measurements of geometrical properties of kernels belonging to three different varieties of wheat: Kama, Rosa, and Canadian. Although the target class (variety) is known, we will approach this task as an **unsupervised learning** problem.\n    a. Download the data set from the given link to the UCI Machine Learning Repository. Note that the data set does not include any column names, so we have to set them manually. From left to right, the columns contain the following measurements: area $A$, perimeter $P$, compactness $C = 4\\pi \\cdot A/P^2$, length of kernel, width of kernel, asymmetry coefficient, length of kernel groove and wheat variety (1 for Kama, 2 for Rosa or 3 for Canadian). Name the columns of the `data.frame` accordingly and transform the wheat variety column into a factor with the `labels` argument set appropriately.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    b. Visualize the following bivariate relationships in a scatter plot: `perimeter` vs. `groove_length`, `kernel_width` vs. `groove_length` and `kernel_length` vs. `groove_length`. Do you see any clearly identifiable groups emerging from these bivariate plots?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    c. Create a new `data.frame` called `seeds_scaled`, which contains all variables except for `variety` and all of them in their scaled version, i.e. with their mean removed and divided by their standard deviation.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    d. On the entire `seeds_scaled` data set, run K-means clustering with different values of $k$ (e.g. from 1 to 10). In each run, extract the within-cluster sum of squares and store the results in a vector named `withinss`. Hint: the within-cluster sum of squares can be obtained under the name `tot.withinss` from the fitted `kmeans` object.\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    e. Plot the number of clusters $k$ (on the x-axis) against the values of `withinss` (on the y-axis). Where is the \"elbow\" in that plot and which value of $k$ do you deem most appropriate as a consequence?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    f. Run K-means clustering again, this time with the optimal $k$ you chose in e. Add the cluster assignment vector (as a factor) to your original `data.frame` and highlight the identified clusters by colour in the bivariate scatter plots from b. Do they match with your expectations regarding the groups you visually identified in b.?\n\n\n\n    ::: {.cell}\n    \n    :::\n\n\n\n    g. Finally, for each cluster, determine which wheat variety appears in it most frequently and **label** the cluster according to that variety. Then create a cross-tabulation of that label with the actual wheat varieties. How well was the K-means algorithm able to identify wheat varieties without having any information about these classes?\n\n\n\n    ::: {.cell}\n    \n    :::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}