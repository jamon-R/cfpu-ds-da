{
  "hash": "28dc78f2c7db2d5d27ae84f6609c1760",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Science and Data Analytics\"\nsubtitle: \"The Data Science Workflow I -- Import, Tidy and Transform\"\nauthor: \"Julian Amon, PhD\"\ndate: \"March 31, 2025\"\ndate-format: long\ninstitute: Charlotte Fresenius Privatuniversit√§t\nfooter: \"Data Science and Data Analytics -- The Data Science Workflow I\"\nformat:\n  revealjs:\n    theme:\n      - default\n      - slides.scss\n    width: 1350\n    height: 900\n    slide-number: true\n    logo: img/UOS_Logo.jpg\n    fig-width: 14\n    controls: true\n    embed-resources: true\nhighlight-style: arrow\nexecute: \n  warning: true\n  echo: true\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# Import\n\n\n\n\n\n\n\n## The Data Science workflow -- Import\n\n![](img/data-science-cycle.002.png){fig-align=\"center\"}\n\n## Importing data into R\n\n-   In order to get our data science workflow started, we need to be able to **import** data from different sources into R.\n-   While there is a huge number of different data formats, we will focus on how to import data stored in two of the most common types of formats, namely:\n    -   Text files (like `csv` or `tsv`)\n    -   Spreadsheets (Excel or Google Sheets)\n-   Before we dive into how to get the data stored in such files into R, we need to be able to find these files on our computer in the first place...\n-   For this, we first have to look into how R orients itself in the **file system** on our computer.\n\n## The file system\n\n-   A computer's file system consists of nested folders (*directories*). It can be visualized as tree structures, with directories branching out from the root.\n-   The **root directory** contains all other directories.\n-   The **working directory** is the current location in the filesystem.\n\n![](img/paths_1.png){fig-align=\"center\"}\n\n## Relative and full paths\n\n-   A **path** lists directory names leading to a file. Think of it like instructions on what folders to click on, and in what order, to find the file. We distinguish:\n    -   **Full paths**: Starts from the root directory, i.e. the very top of the file system hierarchy. An example would be:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    example_path <- system.file(package = \"dslabs\")\n    example_path\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"/home/julian/R/x86_64-pc-linux-gnu-library/4.5/dslabs\"\n    ```\n    \n    \n    :::\n    :::\n\n\n    \n    -   **Relative paths**: Starts from the current working directory. Imagine the current working directory would be `/home/julian`, then the **relative** path to the folder above would simply be:\n\n\n    ::: {.cell}\n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"R/x86_64-pc-linux-gnu-library/4.5/dslabs\"\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   In R, we can use the `list.files` function to explore directories:\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    list.files(example_path)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n     [1] \"data\"        \"DESCRIPTION\" \"extdata\"     \"help\"        \"html\"       \n     [6] \"INDEX\"       \"Meta\"        \"NAMESPACE\"   \"R\"           \"script\"     \n    ```\n    \n    \n    :::\n    :::\n\n\n\n\n## Relative and full paths\n\n![](img/paths_2.png){fig-align=\"center\"}\n\n\n## The working directory\n\n-   When referring to files in your R script, it is highly recommended that you use **relative paths**.\n-   **Reason**: paths are unique to your computer, so if someone else runs your code on their computer, it will not find files whose location is described by absolute paths.\n-   To determine the working directory of your current R session, you can type:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    getwd()\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"/home/julian/Dokumente/Projekte/Lehre/CFPU Data Science und Data Analytics/cfpu-ds-da/slides\"\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   To change the working directory, use the function `setwd`:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    setwd(\"/path/to/your/directory\")\n    ```\n    :::\n\n\n\n    In RStudio, you can alternatively also select the working directory via `Session > Set Working Directory`.\n\n\n## Generating path names\n\n-   Different operating systems have different conventions when specifying paths.\n-   For example, Linux and Mac use forward slashes `/`, while Windows uses backslashes `\\` to separate directories.\n-   The R function `file.path` combines characters to form a complete path, automatically ensuring compatibility with the respective operating system.\n-   This function is useful because we often want to define paths using a variable.\n-   Consider the following example: \n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dir <- system.file(package = \"dslabs\")\n    file.path(dir, \"extdata\", \"murders.csv\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] \"/home/julian/R/x86_64-pc-linux-gnu-library/4.5/dslabs/extdata/murders.csv\"\n    ```\n    \n    \n    :::\n    :::\n\n\n\n    Here the variable `dir` contains the full path for the `dslabs` package (needs to be installed!) and `extdata/murders.csv` is the relative path of a specific `csv` file in that folder.\n\n## Importing data from text files\n\n-   All of us know **text files**. They are easy to open, can be easily read by humans and are easily transferable.\n-   When text files are used to store **tabular data**, line breaks are used to separate rows and a predefined character (the so-called **delimiter**) is used to separate columns within a row. Which one is used can depend on the file format:\n    -   `.csv` (comma-separated values) typically uses comma (`,`) or semicolon (`;`).\n    -   `.tsv` (tab-separated values) typically uses tab (which can be a preset number of spaces or `\\t`).\n    -   `.txt` (\"text\") can use any of the above or a simple space ( )\n-   How we read text files into R depends on the delimiter used. Therefore, we need to have a look at the file to determine the delimiter. \n\n## Importing data from text files\n\nThis is the first couple of lines of the `murders.csv` text file from the `dslabs` package we saw referenced before. It contains the number of gun murders in each US state in the year 2010 as well as each state's population. Clearly, it uses commas (`,`) as delimiter. Also note the use of a **header** in the first row.\n\n![](img/csv_file.png){fig-align=\"center\"}\n\n## Importing data from text files -- `.csv`\n\n-   For **comma-delimited** `csv` files, R offers the function `read.csv` to run on the (full or relative) path of the file. By default, it assumes that **decimal points** are used and that a **header** giving column names is present:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    args(read.csv)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (file, header = TRUE, sep = \",\", quote = \"\\\"\", dec = \".\", \n        fill = TRUE, comment.char = \"\", ...) \n    NULL\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   For **semicolon-delimited** `csv` files, R offers the function `read.csv2` to run on the (full or relative) path of the file. By default, it assumes that **decimal commas** are used and that a **header** giving column names is present.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    args(read.csv2)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (file, header = TRUE, sep = \";\", quote = \"\\\"\", dec = \",\", \n        fill = TRUE, comment.char = \"\", ...) \n    NULL\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Both of these functions return a `data.frame` containing the data from the file.\n\n## Importing data from text files -- `.csv`\n\nAs `murders.csv` is comma-delimited, we use `read.csv` to read it into R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndir <- system.file(package = \"dslabs\")\nmurders_df <- read.csv(file.path(dir, \"extdata\", \"murders.csv\"))\nhead(murders_df, 6) # shows the first 6 rows of the data frame\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       state abb region population total\n1    Alabama  AL  South    4779736   135\n2     Alaska  AK   West     710231    19\n3    Arizona  AZ   West    6392017   232\n4   Arkansas  AR  South    2915918    93\n5 California  CA   West   37253956  1257\n6   Colorado  CO   West    5029196    65\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nNote that the categorical variables (`state`, `abb` and `region`) are imported as `character` vectors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunlist(lapply(murders_df, typeof))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      state         abb      region  population       total \n\"character\" \"character\" \"character\"   \"integer\"   \"integer\" \n```\n\n\n:::\n:::\n\n\n\nFor data analysis purposes, we should probably turn these into factors. But for now, we are only interested in the successful import.\n\n## Importing data from text files -- `.tsv`\n\n-   For **tab-delimited** `tsv` files, R offers the functions `read.delim` and `read.delim2`, again assuming the use of **decimal points** and **decimal commas**, respectively:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    args(read.delim)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (file, header = TRUE, sep = \"\\t\", quote = \"\\\"\", dec = \".\", \n        fill = TRUE, comment.char = \"\", ...) \n    NULL\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    args(read.delim2)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (file, header = TRUE, sep = \"\\t\", quote = \"\\\"\", dec = \",\", \n        fill = TRUE, comment.char = \"\", ...) \n    NULL\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Otherwise, the use is identical to `read.csv`: the function requires the path to the file you want to import and returns a `data.frame` containing the (hopefully) correctly parsed data from the file.\n\n## Importing data from text files -- `.tsv`\n\n![](img/tsv_file.png){.absolute top=\"200\" left=\"10\" width=\"40%\"}\n\n![](img/arrow_delim.png){.absolute top=\"400\" left=\"560\" width=\"17.5%\"}\n\n![](img/read_delim.png){.absolute top=\"200\" left=\"800\" width=\"40%\"}\n\n## Importing data from text files -- `.txt`\n\n-   In fact, all of the functions for importing data discussed so far are just interfaces to the R function `read.table`, which provides the most flexibility when importing data from text files:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    args(read.table)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (file, header = FALSE, sep = \"\", quote = \"\\\"'\", dec = \".\", \n        numerals = c(\"allow.loss\", \"warn.loss\", \"no.loss\"), row.names, \n        col.names, as.is = !stringsAsFactors, tryLogical = TRUE, \n        na.strings = \"NA\", colClasses = NA, nrows = -1, skip = 0, \n        check.names = TRUE, fill = !blank.lines.skip, strip.white = FALSE, \n        blank.lines.skip = TRUE, comment.char = \"#\", allowEscapes = FALSE, \n        flush = FALSE, stringsAsFactors = FALSE, fileEncoding = \"\", \n        encoding = \"unknown\", text, skipNul = FALSE) \n    NULL\n    ```\n    \n    \n    :::\n    :::\n\n\n\n    (As always, to see the meaning of all of these arguments, see `?read.table`)\n-   This function is mostly used directly, when importing data from generic `.txt` files, where the format is often less strictly adhered to than in `csv` or `tsv` files.\n\n## Encoding\n\nNow, we know how to import data into R. So we download some data set, read it into R using the correct function, but then this happens...\n\n![](img/encoding_issue.png){.absolute top=\"300\" left=\"10\" width=\"40%\"}\n\n![](img/arrow_csv.png){.absolute top=\"400\" left=\"560\" width=\"17.5%\"}\n\n![](img/encoding_issue2.png){.absolute top=\"275\" left=\"800\" width=\"40%\"}\n\n## Encoding\n\n-   Such issues occur because of an incorrectly identified **file encoding**.\n-   Encoding refers to how the computer stores character strings as binary 0s and 1s. Examples of encoding systems are:\n    -   **ASCII**: uses 7 bits to represent symbols, enough for all English keyboard characters, but not much more...\n    -   **Unicode** (especially UTF-8): the de-facto standard encoding of the internet, able to represent everything from the English alphabet to German Umlaute to Chinese characters and emojis.\n-   When reading a text file into R, its encoding needs to be known, otherwise the import either fails (see previous slide) or produces gibberish (e.g. German \"H√∂he\" $\\to$ \"H√É¬∂he\").\n\n## Encoding\n\n-   RStudio typically uses **UTF-8** as its default, which works in most cases. If it does not, you can use the `guess_encoding` function of the `readr` package to get insight into the encoding.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(readr)\n    weird_filepath <- file.path(\"../data\", \"calificaciones.csv\")\n    as.data.frame(guess_encoding(weird_filepath))\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n        encoding confidence\n    1 ISO-8859-1       0.92\n    2 ISO-8859-2       0.72\n    3 ISO-8859-9       0.53\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   The function deems the `ISO-8859-1` encoding to be the most likely encoding of the previous file. So we pass this value as the `fileEncoding` argument to `read.csv2`:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    head(read.csv2(weird_filepath, sep = \",\", fileEncoding = \"ISO-8859-1\"), 3)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n        nombre                     f.n.             estampa puntuaci√≥n\n    1  Beyonc√© 04 de septiembre de 1981 2023-09-22 02:11:02       87.5\n    2 Bl√ºmchen      20 de abril de 1980 2023-09-22 03:23:05       99.0\n    3     Jo√£o      10 de junio de 1931 2023-09-21 22:43:28       98.9\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   This time, it worked! üòä\n\n\n## Importing data from spreadsheets\n\n-   Another common way of sharing tabular data is through the use of **spreadsheets**, like Excel or Google Sheets. We will see how to import data in both of these types of documents.\n-   With Excel, spreadsheets typically either have a `.xls` or `.xlsx` file suffix. Note that those are **binary** file formats, i.e. unlike text files, they are not human-readable when opened with a text editor.\n-   Base R does *not* have functionality to import data from Excel spreadsheets. However, the package `readxl` does. Its two main functions are:\n    -   `read_xls` to read Excel spreadsheets with `.xls` ending and\n    -   `read_xlsx` to read Excel spreadsheets with `.xlsx` ending.\n-   These functions allow to select only certain areas of certain sheets, transform data types and much more...\n\n\n## Importing data from spreadsheets\n\nConsider the following simple example. Suppose we have the following `.xlsx`-spreadsheet of famous people that died in 2016:\n\n![](img/spreadsheets_deaths.png){fig-align=\"center\"}\n\n\n## Importing data from spreadsheets\n\n-   Note how we only want to import the range `A5:F15` in the sheet called `other`. We can pass these values as the corresponding arguments to the `read_xlsx` function:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(readxl)\n    args(read_xlsx)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    function (path, sheet = NULL, range = NULL, col_names = TRUE, \n        col_types = NULL, na = \"\", trim_ws = TRUE, skip = 0, n_max = Inf, \n        guess_max = min(1000, n_max), progress = readxl_progress(), \n        .name_repair = \"unique\") \n    NULL\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Hence, to import this data, we should call:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dir <- system.file(package = \"readxl\")\n    xlsx_filepath <- file.path(dir, \"extdata\", \"deaths.xlsx\")\n    head(as.data.frame(read_xlsx(xlsx_filepath, sheet = \"other\", range = \"A5:F15\")), 5)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n                Name Profession Age Has kids Date of birth Date of death\n    1     Vera Rubin  scientist  88     TRUE    1928-07-23    2016-12-25\n    2    Mohamed Ali    athlete  74     TRUE    1942-01-17    2016-06-03\n    3   Morley Safer journalist  84     TRUE    1931-11-08    2016-05-19\n    4   Fidel Castro politician  90     TRUE    1926-08-13    2016-11-25\n    5 Antonin Scalia     lawyer  79     TRUE    1936-03-11    2016-02-13\n    ```\n    \n    \n    :::\n    :::\n\n\n\n\n## Importing data from spreadsheets\n\n-   **Google Sheets** is another widely used spreadsheet program, which is free and web-based. Just like with Excel, in Google Sheets data are organized in worksheets (also called sheets) inside of spreadsheet files.\n-   Again, Base R does *not* have functionality to import data from Google Sheets spreadsheets. However, the package `googlesheets4` does. Its main function is `read_sheet`, which reads a Google Sheet from a URL or a file id.\n-   Given such a URL, its use is very similar to `read_xlsx`:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(googlesheets4)\n    \n    gs4_deauth() # used to read publicly available Google Sheets\n    # Obtaining data on global life expectancy since 1800 from the Gapminder project\n    # For more information, see http://gapm.io/dlex\n    sheet_id <- \"1RehxZjXd7_rG8v2pJYV6aY0J3LAsgUPDQnbY4dRdiSs\"\n    \n    df_gs <- as.data.frame(read_sheet(sheet_id,\n                                      sheet = \"data-for-world-by-year\",\n                                      range = \"A1:D302\"))\n    ```\n    \n    ::: {.cell-output .cell-output-stderr}\n    \n    ```\n    ‚úî Reading from \"_GM-Life Expectancy- Dataset - v14\".\n    ```\n    \n    \n    :::\n    \n    ::: {.cell-output .cell-output-stderr}\n    \n    ```\n    ‚úî Range ''data-for-world-by-year'!A1:D302'.\n    ```\n    \n    \n    :::\n    :::\n\n\n\n\n## Importing data from spreadsheets\n\nNow, the data has successfully been imported:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nkable(head(df_gs, 8)) # the function kable creates nice tables for presentations\n```\n\n::: {.cell-output-display}\n\n\n|geo   |name  | time| Life expectancy|\n|:-----|:-----|----:|---------------:|\n|world |World | 1800|        30.64173|\n|world |World | 1801|        30.71239|\n|world |World | 1802|        30.60052|\n|world |World | 1803|        30.27759|\n|world |World | 1804|        30.19749|\n|world |World | 1805|        30.78082|\n|world |World | 1806|        30.79082|\n|world |World | 1807|        30.73985|\n\n\n:::\n:::\n\n\n\n\n## Importing data in other formats\n\n-   There is **a lot** of other data formats, which can be read into R with the help of other **packages**. The following provides a brief and inevitably incomplete overview:\n    -   Package `haven` for data from SPSS, Stata or SAS.\n    -   Package `DBI` along with a DBMS-specific backend allows you to run SQL queries on a data base and obtain the result as a `data.frame` directly in R.\n    -   Package `jsonline` for importing JSON files.\n    -   Package `xml2` for importing XML files.\n    -   ...\n\n\n# Tidy and Transform\n\n## The Data Science workflow -- Tidy and Transform\n\n![](img/data-science-cycle.003.png){fig-align=\"center\"}\n\n## Tidy and Transform -- Data wrangling\n\n-   After we imported data into R, we want to make it **easily processable** for visualizations or model building. This process could involve:\n    -   renaming columns to avoid confusion and unnecessary typing.\n    -   subsetting the data to use only parts of it, i.e. filtering.\n    -   handling incorrect and/or missing values.\n    -   aggregating the data to compute summary statistics.\n    -   reshaping the data to suit the needs of functions operating on them.\n    -   adding or replacing columns.\n    -   joining other data sets to enrich the information presented.\n    -   and much more...\n-   Jointly, we refer to these tidying and transformation tasks as **data wrangling**.\n\n## Tidy and Transform -- Data wrangling\n\n![](img/data_wrangling.png){fig-align=\"center\"}\n\n## Example data set\n\nLet's import some data that we will be using as an example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- read.csv(file.path(\"../data\", \"nyc13_flights.csv\"))\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year month day actual.time.of.departure scheduled.time.of.departure\n1 2013     1   1                      517                         515\n2 2013     1   1                      533                         529\n3 2013     1   1                      542                         540\n4 2013     1   1                      544                         545\n5 2013     1   1                      554                         600\n6 2013     1   1                      554                         558\n  depature.delay actual.time.of.arrival scheduled.time.of.arrival arrival.delay\n1              2                    830                       819            11\n2              4                    850                       830            20\n3              2                    923                       850            33\n4             -1                   1004                      1022           -18\n5             -6                    812                       837           -25\n6             -4                    740                       728            12\n  carrier flight plane.tail.number origin destination air.time distance\n1      UA   1545            N14228    EWR         IAH      227     1400\n2      UA   1714            N24211    LGA         IAH      227     1416\n3      AA   1141            N619AA    JFK         MIA      160     1089\n4      B6    725            N804JB    JFK         BQN      183     1576\n5      DL    461            N668DN    LGA         ATL      116      762\n6      UA   1696            N39463    EWR         ORD      150      719\n            time.hour\n1 2013-01-01 05:00:00\n2 2013-01-01 05:00:00\n3 2013-01-01 05:00:00\n4 2013-01-01 05:00:00\n5 2013-01-01 06:00:00\n6 2013-01-01 05:00:00\n```\n\n\n:::\n:::\n\n\n\nThis data was adapted from the [nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html) package. It contains information on all 166,158 domestic flights that departed from New York City (airports EWR, JFK and LGA) in the first six months of 2013. The data itself originates from the [US Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr).\n\n## Column naming\n\nThe columns of this data set have quite long and descriptive names. Column names generally should:\n\n-   be as short as possible.\n-   be as long as necessary to be descriptive enough.\n-   not use spaces or special characters.\n-   only contain lowercase letters.\n-   use **snake_case** for multiple words.\n\nThese rules are good to keep in mind also when naming any other R object. Let's see what kind of information is contained in our example data set and how we could name the corresponding columns appropriately.\n\n## Column naming\n\n::: slightlysmall\nOur example data set contains the following columns:\n:::\n\n::: small\n-   `year`, `month`, `day`: date of departure\n-   `actual.time.of.departure`, `scheduled.time.of.departure`: actual and scheduled time of departure (in format HHMM or HMM). Too long, how about `dep_time` and `sched_dep_time`?\n-   `actual.time.of.arrival`, `scheduled.time.of.arrival`: actual and scheduled time of arrival (in format HHMM or HMM). Too long, how about `arr_time` and `sched_arr_time`?\n-   `departure.delay`, `arrival.delay`: departure and arrival delays, in minutes. To be consistent, how about `dep_delay` and `arr_delay`?\n-   `carrier`, `flight`: airline and flight number.\n-   `plane.tail.number`: plane tail number. Too long, how about `tailnum`?\n-   `origin`, `destination`: origin and destination airport. `origin` fine, but maybe `dest`?\n-   `air.time`: amount of time spent in the air, in minutes. Change to `air_time`?\n-   `distance`: distance between airports, in miles.\n-   `time.hour`: scheduled date and hour of the flight. Change to `time_hour`?\n:::\n\n## Column naming\n\nTo reset the column names of a `data.frame`, we can either use `colnames` or `names`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(names(flights))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"year\"                        \"month\"                      \n[3] \"day\"                         \"actual.time.of.departure\"   \n[5] \"scheduled.time.of.departure\" \"depature.delay\"             \n```\n\n\n:::\n\n```{.r .cell-code}\nnames(flights) <- c(\"year\", \"month\", \"day\", \"dep_time\", \"sched_dep_time\", \"dep_delay\",\n                    \"arr_time\", \"sched_arr_time\", \"arr_delay\", \"carrier\", \"flight\",\n                    \"tail_num\", \"origin\", \"dest\", \"air_time\", \"distance\", \"time_hour\")\nhead(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n1 2013     1   1      517            515         2      830            819\n2 2013     1   1      533            529         4      850            830\n3 2013     1   1      542            540         2      923            850\n4 2013     1   1      544            545        -1     1004           1022\n5 2013     1   1      554            600        -6      812            837\n6 2013     1   1      554            558        -4      740            728\n  arr_delay carrier flight tail_num origin dest air_time distance\n1        11      UA   1545   N14228    EWR  IAH      227     1400\n2        20      UA   1714   N24211    LGA  IAH      227     1416\n3        33      AA   1141   N619AA    JFK  MIA      160     1089\n4       -18      B6    725   N804JB    JFK  BQN      183     1576\n5       -25      DL    461   N668DN    LGA  ATL      116      762\n6        12      UA   1696   N39463    EWR  ORD      150      719\n            time_hour\n1 2013-01-01 05:00:00\n2 2013-01-01 05:00:00\n3 2013-01-01 05:00:00\n4 2013-01-01 05:00:00\n5 2013-01-01 06:00:00\n6 2013-01-01 05:00:00\n```\n\n\n:::\n:::\n\n\n\n## Checking data types\n\nNext, we should make sure that the data type and/or class used for each variable suits the data presented in this variable. In particular:\n\n-   Each numerical variable should of type `integer` or `double`.\n-   Each categorical variable should be a `factor`.\n-   Each non-categorical text-based variable should be of type `character`.\n-   Each date / date-time variable should be a `Date` or a `POSIXct`, respectively.\n\nLet's have a look in our data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsapply(flights, typeof)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          year          month            day       dep_time sched_dep_time \n     \"integer\"      \"integer\"      \"integer\"      \"integer\"      \"integer\" \n     dep_delay       arr_time sched_arr_time      arr_delay        carrier \n     \"integer\"      \"integer\"      \"integer\"      \"integer\"    \"character\" \n        flight       tail_num         origin           dest       air_time \n     \"integer\"    \"character\"    \"character\"    \"character\"      \"integer\" \n      distance      time_hour \n     \"integer\"    \"character\" \n```\n\n\n:::\n:::\n\n\n\n## Adapting data types\n\nMost of the data types in our data set seem appropriate, however we should:\n\n-   redefine `carrier`, `tail_num`, `origin` and `dest` to be a `factor`.\n-   redefine `time_hour` to be a `POSIXct` date-time.\n\nUsing the function `factor`, the first part should be no problem:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactor_vars <- c(\"carrier\", \"tail_num\", \"origin\", \"dest\")\nfor(var in factor_vars){\n  flights[[var]] <- factor(flights[[var]])\n  print(head(flights[[var]]))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] UA UA AA B6 DL UA\nLevels: 9E AA AS B6 DL EV F9 FL HA MQ OO UA US VX WN YV\n[1] N14228 N24211 N619AA N804JB N668DN N39463\n3825 Levels: D942DN N0EGMQ N10156 N102UW N103US N104UW N10575 N105UW ... N9EAMQ\n[1] EWR LGA JFK JFK LGA EWR\nLevels: EWR JFK LGA\n[1] IAH IAH MIA BQN ATL ORD\n100 Levels: ABQ ACK ALB ATL AUS AVL BDL BGR BHM BNA BOS BQN BTV BUF BUR ... XNA\n```\n\n\n:::\n:::\n\n\n\n## Date-times\n\n-   In the previous lecture, we have talked about **dates** in R, but we have not talked about how to represent **time**.\n-   As simple as time seem to be, representing time-related information with a computer can be incredibly complex. Think about:\n    -   time zones (changing in geographical composition over time),\n    -   daylight saving time (DST) and its relevance in different countries,\n    -   different formats for writing dates and times (e.g. 16:00 vs. 4:00 pm),\n    -   ...\n-   In this course, we will fortunately stick to relatively simple cases. However, data in the real world does not always behave that nicely...\n\n## Date-times\n\n![](img/timezones.png){fig-align=\"center\"}\n\nThis [map](https://en.wikipedia.org/wiki/Tz_database#/media/File:Timezone-boundary-builder_release_2023d.png) partitions the world into regions where local clocks all show the same time and have done so since 1970. Talk about complexity...\n\n## Date-time in R -- POSIXct\n\nOne way of representing date-time information in R is with the `POSIXct` class. Just as with dates, we can use **format strings** also to identify hour, minute, second, time zone, etc.\n\nIn our `flights` data set, the variable `time_hour` has a relatively simple format:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(flights$time_hour)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2013-01-01 05:00:00\" \"2013-01-01 05:00:00\" \"2013-01-01 05:00:00\"\n[4] \"2013-01-01 05:00:00\" \"2013-01-01 06:00:00\" \"2013-01-01 05:00:00\"\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nAdditionally, we know that these are all times from the NYC time zone. In R, we can make use of a data base of time zones with the help of the function `OlsonNames`, named after the original creator Arthur David Olson. In there, there is a time zone called **America/New_York**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nOlsonNames()[170]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"America/Nassau\"\n```\n\n\n:::\n:::\n\n\n\n## Date-time in R -- POSIXct\n\nNow, we can use the appropriate format string and time zone name to turn the `time_hour` variable into a `POSIXct` date-time. For this purpose, we require the function `as.POSIXct`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$time_hour <- as.POSIXct(flights$time_hour,\n                                tz = \"America/New_York\",\n                                format = \"%Y-%m-%d %H:%M:%S\")\ntypeof(flights$time_hour)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"double\"\n```\n\n\n:::\n\n```{.r .cell-code}\nclass(flights$time_hour)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"POSIXct\" \"POSIXt\" \n```\n\n\n:::\n\n```{.r .cell-code}\nhead(flights$time_hour, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2013-01-01 05:00:00 EST\" \"2013-01-01 05:00:00 EST\"\n```\n\n\n:::\n\n```{.r .cell-code}\ntail(flights$time_hour, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2013-06-30 20:00:00 EDT\" \"2013-06-30 19:00:00 EDT\"\n```\n\n\n:::\n:::\n\n\n\nNote how these `POSIXct` date-times now have `EST` (Eastern Standard Time) or `EDT` (Eastern Daylight Time) on them to indicate the time zone. `as.POSIXct` automatically applied the daylight saving time for the correct period.\n\n## Filtering\n\nNow that we have the correct data types, we might want to **filter** our `data.frame`. **Filtering** refers to the process of keeping rows based on certain conditions imposed on the values of the columns. For example, we might want to find all flights on 14th February that were more than one hour delayed upon arrival at their destination.\n\n. . . \n\nWe can filter a `data.frame` by **logical subsetting** of the rows. For this, we have to combine the conditions we want to impose by using the logical operators, `&` (**and**), `|` (**or**) and `!` (**not**). If we want to find the carriers and flight numbers of the aforementioned flights, we could do:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(flights[flights$month == 2 & flights$day == 14 & flights$arr_delay > 60,\n             c(\"year\", \"month\", \"day\", \"carrier\", \"flight\", \"arr_delay\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      year month day carrier flight arr_delay\n38528 2013     2  14      9E   4023        92\n38551 2013     2  14      DL    807       143\n38604 2013     2  14      B6     56       118\n38613 2013     2  14      B6    600        65\n38623 2013     2  14      DL   1959       200\n38624 2013     2  14      UA    517        95\n```\n\n\n:::\n:::\n\n\n\n## Filtering\n\nLet's see another example: suppose we want to find all flights that left from either Newark (EWR) or JFK to Los Angeles (LAX) on 14th February after 6:00 pm. We could do:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights[flights$month == 2 & \n          flights$day == 14 & \n          (flights$origin == \"EWR\" | flights$origin == \"JFK\") & \n          flights$dest == \"LAX\" & \n          flights$dep_time > 1800,\n        c(\"year\", \"month\", \"day\", \"carrier\", \"flight\", \"origin\", \"dest\", \"dep_time\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      year month day carrier flight origin dest dep_time\n39020 2013     2  14      AA    119    EWR  LAX     1812\n39076 2013     2  14      DL     87    JFK  LAX     1906\n39111 2013     2  14      AA     21    JFK  LAX     1943\n39146 2013     2  14      VX    415    JFK  LAX     2017\n39150 2013     2  14      UA    771    JFK  LAX     2027\n39184 2013     2  14      DL   2363    JFK  LAX     2118\n39185 2013     2  14      B6    677    JFK  LAX     2118\n39201 2013     2  14      AA    185    JFK  LAX     2147\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nNote that -- since there are only three possible `origin` airports in this data set -- we could replace the third condition with\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$origin != \"LGA\"\n```\n:::\n\n\n\n\n## Filtering\n\nThat starts to be quite a lot of typing... To reduce the number of times that we have to type the name of the `data.frame`, we can use the `subset` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubset(flights,\n       month == 2 & day == 14 & origin != \"LGA\" & dest == \"LAX\" & dep_time > 1800,\n       c(year, month, day, carrier, flight, origin, dest, dep_time))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      year month day carrier flight origin dest dep_time\n39020 2013     2  14      AA    119    EWR  LAX     1812\n39076 2013     2  14      DL     87    JFK  LAX     1906\n39111 2013     2  14      AA     21    JFK  LAX     1943\n39146 2013     2  14      VX    415    JFK  LAX     2017\n39150 2013     2  14      UA    771    JFK  LAX     2027\n39184 2013     2  14      DL   2363    JFK  LAX     2118\n39185 2013     2  14      B6    677    JFK  LAX     2118\n39201 2013     2  14      AA    185    JFK  LAX     2147\n```\n\n\n:::\n:::\n\n\n\nThis is much more clear and compact. Note that when using `subset`, the names of the columns we want to select do not have to be specified with quotation marks `\"\"`.\n\n\n## Handling missing values\n\nLet's see where in our data set we have **missing values** (indicated by `NA`):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_missing <- sapply(flights, function(x) sum(is.na(x)))\nn_missing[n_missing > 0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n dep_time dep_delay  arr_time arr_delay  tail_num  air_time \n     4883      4883      5101      5480      1521      5480 \n```\n\n\n:::\n:::\n\n\n\n. . .\n\nOnly six variables seem to have missing values. Note how in this data set, the missing values can be **interpreted**:\n\n-   `dep_time` and `dep_delay` $\\to$ flight was **cancelled**. In these cases, `arr_time` and `arr_delay` are also `NA`.\n-   Additional missing values in `arr_time` $\\to$ flight was **diverted** to another destination airport.\n-   Additional missing values in `arr_delay` and `air_time`. Unknown reason for missingness, hard to construct without additional information.\n-   In some cases, the `tail_num` of the plane seems to be simply unknown.\n\n\n## Handling missing values\n\nLet's start handling the cancelled flights first. Depending on the circumstances, we might want to add a variable to indicate a cancelled flight, like so...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$cancelled <- is.na(flights$dep_time)\nhead(flights[, c(\"year\", \"month\", \"day\", \"dep_time\", \"arr_time\",\n                 \"carrier\", \"flight\", \"cancelled\")], 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year month day dep_time arr_time carrier flight cancelled\n1 2013     1   1      517      830      UA   1545     FALSE\n2 2013     1   1      533      850      UA   1714     FALSE\n3 2013     1   1      542      923      AA   1141     FALSE\n4 2013     1   1      544     1004      B6    725     FALSE\n5 2013     1   1      554      812      DL    461     FALSE\n```\n\n\n:::\n:::\n\n\n\n. . .\n\n... or remove cancelled flights from the data set all together and put them into their own `data.frame`. Let's go for that option:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncancelled_flights <- flights[is.na(flights$dep_time), ]\nflights <- flights[!is.na(flights$dep_time), ]\nhead(cancelled_flights[, c(\"year\", \"month\", \"day\", \"dep_time\", \"arr_time\",\n                           \"carrier\", \"flight\", \"cancelled\")], 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     year month day dep_time arr_time carrier flight cancelled\n839  2013     1   1       NA       NA      EV   4308      TRUE\n840  2013     1   1       NA       NA      AA    791      TRUE\n841  2013     1   1       NA       NA      AA   1925      TRUE\n842  2013     1   1       NA       NA      B6    125      TRUE\n1778 2013     1   2       NA       NA      EV   4352      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n## Handling missing values\n\nNext, let's do the same also with diverted flights, which will contain all remaining flights that have `NA`s in the `arr_time` variable:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiverted_flights <- flights[is.na(flights$arr_time), ]\nflights <- flights[!is.na(flights$arr_time), ]\nhead(diverted_flights[, c(\"year\", \"month\", \"day\", \"dep_time\", \"arr_time\",\n                          \"carrier\", \"flight\", \"origin\", \"dest\")], 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     year month day dep_time arr_time carrier flight origin dest\n755  2013     1   1     2016       NA      EV   4204    EWR  OKC\n1715 2013     1   2     2041       NA      B6    147    JFK  RSW\n1757 2013     1   2     2145       NA      UA   1299    EWR  RSW\n7040 2013     1   9      615       NA      9E   3856    JFK  ATL\n7852 2013     1   9     2042       NA      B6    677    JFK  LAX\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nLet's look at how many missing values are remaining after separating out cancelled and diverted flights from our data set:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_missing <- sapply(flights, function(x) sum(is.na(x)))\nn_missing[n_missing > 0]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narr_delay  air_time \n      379       379 \n```\n\n\n:::\n:::\n\n\n\nOnly a small number of `NA`s are remaining in the variables `arr_delay` and `air_time`. We will deal with them when we need to...\n\n\n## Descriptive statistics -- Numeric variables\n\nNow, we are finally ready to compute some descriptive statistics. Say, we want to know the average departure and arrival delay of a (not cancelled or diverted) flight. We use the function `mean`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(flights$dep_delay)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 13.65542\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(flights$arr_delay)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] NA\n```\n\n\n:::\n:::\n\n\n\nThe average departure delay is around 13.6 minutes, but the average arrival delay is `NA`? Why is that?\n\n. . .\n\nOf course, that's exactly because of the remaining missing values in `arr_delay`. R cannot know the average of a vector of values where some values are unknown. However, most functions for descriptive statistics have an argument called `na.rm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(flights$arr_delay, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8.15129\n```\n\n\n:::\n:::\n\n\n\n\n## Descriptive statistics -- Numeric variables\n\nLet's say we wanted to know what the maximum departure and arrival delays were. In that case, we would use the function `max` and also set its `na.rm` option to `TRUE` (strictly necessary only for `arr_delay`):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmax(flights$dep_delay, na.rm = TRUE) / 60 # divide by 60 to get hours from minutes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21.68333\n```\n\n\n:::\n\n```{.r .cell-code}\nmax(flights$arr_delay, na.rm = TRUE) / 60 # divide by 60 to get hours from minutes\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 21.2\n```\n\n\n:::\n:::\n\n\n\nSo both maximum departure and arrival delays were over 21 hours!\n\n. . .\n\nOther functions for important univariate descriptive statistics of numeric variables are:\n\n-   `range` for both `min` and `max` in one go.\n-   `median` and `quantile` for quantiles.\n-   `var` and `sd` for variance and standard deviation.\n-   `fivenum` and `summary` for five-point summaries.\n\n\n## Descriptive statistics -- Categorical variables\n\nFrom categorical variables, we very often want to compute a **frequency table**. This can be achieved with the R function `table`. Let's say we want to know how many flights started from each of the three NYC airports:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Absolute frequencies:\ntable(flights$origin)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  EWR   JFK   LGA \n58649 54097 48311 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Relative frequencies:\nprop.table(table(flights$origin))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      EWR       JFK       LGA \n0.3641506 0.3358873 0.2999621 \n```\n\n\n:::\n:::\n\n\n\n. . .\n\nOr we want to know the distribution of carriers operating out of LaGuardia in %:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nround(prop.table(table(flights$carrier[flights$origin == \"LGA\"]))*100, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   9E    AA    AS    B6    DL    EV    F9    FL    HA    MQ    OO    UA    US \n 1.10 15.24  0.00  6.14 24.03  5.64  0.69  3.68  0.00 16.70  0.00  7.78 12.84 \n   VX    WN    YV \n 0.00  5.70  0.46 \n```\n\n\n:::\n:::\n\n\n\n\n## Descriptive statistics -- Grouping\n\nA very common action in data wrangling is computing statistics of a variable for each level of a categorical variable. In our `flights` data, we might be interested for example in:\n\n-   the average departure delay for each carrier,\n-   the median arrival delay in each month broken down by NYC airport,\n-   the fastest air time for each route,\n-   ...\n\nSuch actions require us to **group** the data by the factor levels of the categorical variable and then compute statistics on the variable of interest for each of the resulting groups.\n\n\n## Descriptive statistics -- Grouping\n\nIn R, this kind of action can be achieved with the functions `tapply` and `aggregate`. Let's first look at how `tapply` works for the three examples given on the previous slide:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Average departure delay by carrier:\ntapply(flights$dep_delay, flights$carrier, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       9E        AA        AS        B6        DL        EV        F9        FL \n18.238843  9.987883  8.058333 13.796756  9.530427 23.308381 24.197605 14.879078 \n       HA        MQ        OO        UA        US        VX        WN        YV \n11.845304 11.580444 63.000000 12.404769  3.938624 14.777251 17.169844 22.549550 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Median arrival delay for each month and airport\ntapply(flights$arr_delay, list(flights$origin, flights$month), median, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     1  2  3  4  5  6\nEWR  0 -2 -4 -1 -6 -1\nJFK -7 -5 -7 -4 -9 -1\nLGA -4 -4 -7 -2 -9 -4\n```\n\n\n:::\n\n```{.r .cell-code}\n# Fastest air time on each route\nhead(tapply(flights$air_time, paste0(flights$origin, \"_\", flights$dest), min, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEWR_ALB EWR_ATL EWR_AUS EWR_AVL EWR_BDL EWR_BNA \n     24      88     181      76      20      70 \n```\n\n\n:::\n:::\n\n\n\n\n## Descriptive statistics -- Grouping\n\nSo `tapply` generally works like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(variable_of_interest, list_of_grouping_variables, aggregation_function, ...)\n```\n:::\n\n\n\n. . .\n\nBy contrast, the function `aggregate` works like this:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregate(df_of_interest, list_of_grouping_variables, aggregation_function, ...)\n```\n:::\n\n\n\n`aggregate` then applies the `aggregation_function` to each variable in the `df_of_interest` by group.\n\n. . .\n\nSo, we can compute both average departure and arrival delays by carrier in one go, for example:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(aggregate(flights[,c(\"dep_delay\", \"arr_delay\")],\n               list(flights$carrier),\n               mean, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Group.1 dep_delay arr_delay\n1      9E 18.238843  9.519527\n2      AA  9.987883  1.475949\n3      AS  8.058333 -3.036415\n4      B6 13.796756 10.410469\n5      DL  9.530427  1.745742\n6      EV 23.308381 20.328515\n```\n\n\n:::\n:::\n\n\n\n\n## Descriptive statistics -- Grouping with `cut`\n\n-   A frequently encountered goal is to group not based on an existing categorical variable, but on different **intervals** of a numeric variable.\n-   For example, we might be interested in analyzing delay patterns based on **air time**: short-haul ($\\leq$ 3 hours), medium-haul (3-6 hours) and long-haul (6-16 hours) (according to the [IATA](https://en.wikipedia.org/wiki/Flight_length#Time-based_definitions)).\n-   To group by these flight length categories, we have to **cut** our `air_time` variable at these cut points. For this, we can use the function `cut`.\n-   Besides specifying the cut points, `cut` offers us also to **label** the levels of the resulting `factor`.\n\n\n## Descriptive statistics -- Grouping with `cut`\n\nSo to add this variable to our `data.frame`, we might do:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights$length_cat <- cut(flights$air_time, c(0, 180, 360, Inf),\n                          labels = c(\"short-haul\", \"medium-haul\", \"long-haul\"))\n\nhead(flights[, c(\"year\", \"month\", \"day\", \"dep_time\", \"arr_time\",\n                 \"origin\", \"dest\", \"air_time\", \"length_cat\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year month day dep_time arr_time origin dest air_time  length_cat\n1 2013     1   1      517      830    EWR  IAH      227 medium-haul\n2 2013     1   1      533      850    LGA  IAH      227 medium-haul\n3 2013     1   1      542      923    JFK  MIA      160  short-haul\n4 2013     1   1      544     1004    JFK  BQN      183 medium-haul\n5 2013     1   1      554      812    LGA  ATL      116  short-haul\n6 2013     1   1      554      740    EWR  ORD      150  short-haul\n```\n\n\n:::\n:::\n\n\n\nNow, we can analyse average departure and arrival delays by these categories using `aggregate`, for instance:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naggregate(flights[,c(\"dep_delay\", \"arr_delay\")],\n          list(flights$length_cat), mean, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Group.1 dep_delay arr_delay\n1  short-haul  14.55357  10.06333\n2 medium-haul  11.22840   2.39164\n3   long-haul  10.17673  16.59834\n```\n\n\n:::\n:::\n\n\n\n\n## Joining tables\n\nOur `flights` data set only contains codes for carrier, air plane and airports. To properly understand this data, we need to be able to **enrich** this data set by more information, such as:\n\n-   Full name of the carrier\n-   Full name and location of the origin and destination airports\n-   Type, model and size of the aircraft used\n-   Weather information at the origin airport at the time of departure\n\nIndeed, any moderately complex data science project will involve **multiple tables** that must be **joined** together in order to answer the questions that you are interested in.\n\n\n## Joining tables\n\nThe [nycflights13](https://cran.r-project.org/web/packages/nycflights13/index.html) package contains four additional tables that can be joined into the `flights` table. The below graph illustrates their relation:\n\n![](img/nycflights13_data.png){fig-align=\"center\"}\n\n## Joining tables\n\nTherefore, in the `flights` data set, \n\n-   the variables `origin` and `dest` are foreign keys that correspond to the primary key `faa` in `airports`.\n-   the variable `tail_num` is a foreign key that corresponds to the primary key `tail_num` in `planes`.\n-   the variable `carrier` is a foreign key that corresponds to the primary key `carrier` in `airlines`.\n-   the variables `origin` and `time_hour` constitute a **compound** foreign key that corresponds to the compound primary key constituted by `origin` and `time_hour` in `weather`.\n\nTo illustrate how we can **join** information from these tables into `flights` using keys, we start with the easiest example of `airlines`.\n\n## Joining tables\n\nFor this, we have to read in the `airlines` table and inspect it:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairlines <- read.csv(file.path(\"../data\", \"nyc13_airlines.csv\"))\nairlines\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   carrier                        name\n1       9E           Endeavor Air Inc.\n2       AA      American Airlines Inc.\n3       AS        Alaska Airlines Inc.\n4       B6             JetBlue Airways\n5       DL        Delta Air Lines Inc.\n6       EV    ExpressJet Airlines Inc.\n7       F9      Frontier Airlines Inc.\n8       FL AirTran Airways Corporation\n9       HA      Hawaiian Airlines Inc.\n10      MQ                   Envoy Air\n11      OO       SkyWest Airlines Inc.\n12      UA       United Air Lines Inc.\n13      US             US Airways Inc.\n14      VX              Virgin America\n15      WN      Southwest Airlines Co.\n16      YV          Mesa Airlines Inc.\n```\n\n\n:::\n:::\n\n\n\nThis is a very simple and small data set with the carrier code and name of 16 American airline companies. Now, how do we join this information into the `flights` data set?\n\n\n## Joining tables -- Types of joins\n\n-   There are many different **types of joins** that determine how two (or more) tables are brought together. We will illustrate only the most important ones with a toy example.\n-   Say, we have two tables, `x` and `y`, each with a `key` column and a column containing some values:\n\n    ![](img/joins_setup.png){fig-align=\"center\" width=\"25%\"}\n    \n    The colored key columns map background color to key value. The grey columns represent \"value\" columns. \n    \n## Joining tables -- Inner join\n\n-   In an **inner join**, we want to keep only the rows that have information in both tables.\n-   In the example, this is only the case for data points with `key` 1 and 2. Therefore, the rows with `key` 3 and 4 do not make it to the joined table, if we join `x` and `y` on an inner join:\n\n    ![](img/joins_inner.png){fig-align=\"center\" width=\"50%\"}\n    \n## Joining tables -- Left outer join\n\n-   In a **left outer join**, we want to keep all rows in the **left table** (in this case `x`). Rows without a matching `key` in `y` receive `NA` for the value column of `y`:\n\n    ![](img/joins_left.png){fig-align=\"center\" width=\"50%\"}\n    \n-   For simplicity, such joins are usually simply called **left joins**.\n\n## Joining tables -- Right outer join\n\n-   In a **right outer join**, we want to keep all rows in the **right table** (in this case `y`). Rows without a matching `key` in `x` receive `NA` for the value column of `x`:\n\n    ![](img/joins_right.png){fig-align=\"center\" width=\"50%\"}\n    \n-   For simplicity, such joins are usually simply called **right joins**.\n\n## Joining tables -- Full outer join\n\n-   In a **full outer join**, we want to keep all the rows across both tables and fill the missing values with `NA`s:\n\n    ![](img/joins_full.png){fig-align=\"center\" width=\"50%\"}\n    \n-   For simplicity, such joins are usually simply called **full joins**.\n\n## Performing joins with `merge`\n\nIn R, joining happens with the help of the function `merge`, whose arguments can be quite confusing at times... Here is the breakdown of the most important ones:\n\n-   `x` and `y` are the left and right `data.frame` to join.\n-   `by` is the name of the key(s) used for joining, if the column name of this key is the same in both `x` and `y`. If not, we specify the column names in `x` via the `by.x` argument and in `y` via the `by.y` argument.\n-   The arguments `all`, `all.x` and `all.y` specify the type of join:\n    -   Set `all` to `FALSE` for an **inner join**.\n    -   Set `all.x` to `TRUE` for a **left join**.\n    -   Set `all.y` to `TRUE` for a **right join**.\n    -   Set `all` to `TRUE` for a **full outer join**.\n\n\n## Performing joins with `merge`\n\nSo let's finally see joins in action! We **left join** the `airlines` data set into `flights` on the key of `carrier`. So, to do this in R, we run:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights <- merge(flights, airlines, by = \"carrier\", all.x = TRUE)\nhead(flights[, c(\"year\", \"month\", \"day\", \"dep_time\", \"origin\", \"dest\", \"carrier\", \"name\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  year month day dep_time origin dest carrier              name\n1 2013     5  19     2034    LGA  TYS      9E Endeavor Air Inc.\n2 2013     4  28     1621    JFK  MKE      9E Endeavor Air Inc.\n3 2013     4  23      749    EWR  CVG      9E Endeavor Air Inc.\n4 2013     6   5     2049    JFK  DCA      9E Endeavor Air Inc.\n5 2013     1  19     1944    JFK  IAD      9E Endeavor Air Inc.\n6 2013     6  27     1939    LGA  DAY      9E Endeavor Air Inc.\n```\n\n\n:::\n:::\n\n\n\nNote two things about this successful join:\n\n-   First, in the `airlines` data set, we found a match for every carrier in `flights`, so the left join did not produce any `NA`s. Proof:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    sum(is.na(flights$name))\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1] 0\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Second, `merge` changed the order of the rows of the `data.frame`.\n\n\n## Tidy data\n\n-   To finish this chapter, let's talk about **tidy data**.\n-   Rather than just meaning \"clean\", tidy data actually refers to a specific way of organizing your data that is beneficial for the types of actions we want to perform on them. There are three interrelated rules that make data tidy:\n    -   Each variable is a column; each column is a variable.\n    -   Each observation is a row; each row is an observation.\n    -   Each value is a cell; each cell is a single value.\n-   These rules might seem pretty obvious, but actually, most real-world data sets do not meet these requirements as data is often organized to facilitate some goal other than analysis.\n\n\n## Tidy data\n\n-   To illustrate this point, we will have a look a new data set. It contains the fertility rates in Germany and South Korea in the years 1960 to 2015:\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    fertility <- read.csv(file.path(\"../data\", \"fertility.csv\"))\n    fertility[, 1:12]\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n          country X1960 X1961 X1962 X1963 X1964 X1965 X1966 X1967 X1968 X1969 X1970\n    1     Germany  2.41  2.44  2.47  2.49  2.49  2.48  2.44  2.37  2.28  2.17  2.04\n    2 South Korea  6.16  5.99  5.79  5.57  5.36  5.16  4.99  4.85  4.73  4.62  4.53\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n    dim(fertility)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    [1]  2 57\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   This data is **untidy**. Why?\n    -   It contains a variable (namely the year) in **column names**, but according to the principles of tidy data, each variable should be its own column.\n    -   The observations are fertility rates in two countries, so these values should be organized in **rows**.\n\n\n## Tidy data\n\nDue to its shape, such data is said to be in a **wide format** (few rows, lots of columns). We want to reshape it to **long format** (lots of rows, few columns). For this purpose, we use the R function `reshape`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfertility_long <- reshape(fertility, direction = \"long\",\n                          varying = list(names(fertility)[-1]), v.names = \"fertility_rate\",\n                          idvar = \"country\",\n                          timevar = \"year\", times = 1960:2015)\nrownames(fertility_long) <- NULL\nhead(fertility_long, 8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      country year fertility_rate\n1     Germany 1960           2.41\n2 South Korea 1960           6.16\n3     Germany 1961           2.44\n4 South Korea 1961           5.99\n5     Germany 1962           2.47\n6 South Korea 1962           5.79\n7     Germany 1963           2.49\n8 South Korea 1963           5.57\n```\n\n\n:::\n:::\n\n\n\nNow, the data is **tidy**! Note that it is exactly the same underlying data, just represented in a slightly different way.\n\n\n## Tidy data\n\nThe function `reshape` takes some practice to get used to. But once we know how to get our data **tidy**, there are multiple advantages to using this consistent way of organizing your data:\n\n-   As we will see, many functions for data analysis in R cannot be used, unless the data is tidy. This applies in particular to the visualizations we will create with the `ggplot2` package.\n-   Consistent data structures are easier to work with. If every data set \"looks and feels\" the same, you can build routines that will make your analyses more efficient and effective.\n-   Having variables consistently in columns is particularly sensible in R due to its **vectorized nature**. R performs at its best when it is able to run functions on vectors of values. With a tidy data format, we can fully leverage this potential.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}