{
  "hash": "810bbb4134ef820ad67732ff8be502da",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Science and Data Analytics\"\nsubtitle: \"Introduction to Data Science\"\nauthor: \"Julian Amon, PhD\"\ndate: \"March 14, 2025\"\ndate-format: long\ninstitute: Charlotte Fresenius Privatuniversität\nfooter: \"Data Science and Data Analytics -- Introduction\"\nformat:\n  revealjs:\n    theme:\n      - default\n      - slides.scss\n    width: 1350\n    height: 900\n    slide-number: true\n    logo: img/UOS_Logo.jpg\n    fig-width: 14\n    controls: true\n    embed-resources: true\nhighlight-style: arrow\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# What is Data Science?\n\n\n\n\n\n\n\n## Data Science -- A sexy profession in 2012?\n\n![](img/hbr_article1.png){fig-align=\"center\" width=\"76%\"}\n\n::: xxsmall\nSource: [Harvard Business Review](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century) in October 2012\n:::\n\n## Data Science -- A sexy profession today?\n\n![](img/hbr_article2.png){fig-align=\"center\" width=\"90.25%\"}\n\n::: xxsmall\nSource: [Harvard Business Review](https://hbr.org/2022/07/is-data-scientist-still-the-sexiest-job-of-the-21st-century) in July 2022\n:::\n\n## What is Data Science?\n\n![](img/anyideas.png){fig-align=\"center\" width=\"100%\"}\n\n## What is Data Science?\n\n**Data science** is an interdisciplinary academic field that combines statistics, mathematics and computing with specific subject matter expertise to uncover actionable insights hidden in an organization's data.\n\n![](img/dsvenn.png){fig-align=\"center\" width=\"50%\"}\n\n<!-- ```{=html} -->\n\n<!-- <iframe width=\"1300\" height=\"800\" src=\"https://en.wikipedia.org/wiki/Data_science\" title=\"Webpage example\"></iframe> -->\n\n<!-- ``` -->\n\n## A brief history of Data Science\n\n::: incremental\n-   **1962**: Statistician John Tukey describes a field he calls *data analysis*, similar to what we now understand to be data science.\n-   **1974**: Computer scientist Peter Naur proposes the term *data science*, but in a different sense to today, namely as an alternative name for computer science.\n-   **1992**: Conference participants at the University of Montpellier II acknowledge the emergence of a new, inherently interdisciplinary field called *data science* focused on gaining insight from very diverse types of data.\n-   **2001**: William S. Cleveland introduces data science as its own discipline in his article [Data Science: An Action Plan for Expanding the Technical Areas of the Field of Statistics](https://www.jstor.org/stable/1403527).\n-   **2003**: Columbia University starts publishing *The Journal of Data Science*.\n-   **2012**: With the HBR article on data scientist as the \"sexiest job of the 21st century\", the term finds its way from the scientific realm into the mainstream.\n:::\n\n## A brief history of Data Science\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](01_Introduction_to_DS_files/figure-revealjs/unnamed-chunk-2-1.png){width=1344}\n:::\n:::\n\n\n\n## Data Science and Artificial Intelligence (AI)\n\nSince the arrival of ChatGPT, everyone is talking about AI...\n\n![](img/chatgpt_headlines.png){fig-align=\"center\" width=\"75%\"}\n\nIs Data Science = AI? How are the two related?\n\n## Data Science and Artificial Intelligence (AI)\n\nTo answer these questions, we first need some further definitions:\n\n::::: columns\n::: {.slightlysmall .column width=\"50%\"}\n-   **Artificial Intelligence** (AI) is the broad field of developing machines that can replicate human behaviour, including tasks related to perception, reasoning, learning and problem-solving.\n-   One way of achieving this is through **Machine Learning** (ML) algorithms that detect patterns in large data sets and learn to make predictions from them.\n-   **Deep Learning** (DL) is an advanced branch of ML based on so-called neural networks. Innovations in this field are responsible for recent AI breakthroughs, such as ChatGPT.\n:::\n\n::: {.column .fragment width=\"50%\"}\n![](img/ai_venn.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::::\n\n## Data Science at the heart of AI\n\n::::: columns\n::: {.slightlysmall .column width=\"50%\"}\n-   With all of these fields, data science has significant **overlap**, but nonetheless, constitutes its own discipline.\n-   Analogously, there are branches of AI (e.g. robotics or symbolic reasoning) that do *not* revolve around learning patterns from various data sources.\n-   Many of the advances in AI require precisely the **interdisciplinary** combination of computer science, maths, statistics and domain expertise that data science provides.\n-   And yet, a data scientist does much more than develop and apply algorithms for AI...\n:::\n\n::: {.column width=\"50%\"}\n![](img/ai_ml_dl_ds_venn.png){.absolute top=\"180\" left=\"700\" width=\"50%\"}\n:::\n:::::\n\n# What does a Data Scientist do?\n\n## So what does a Data Scientist do?\n\n::::: columns\n::: {.slightlysmall .column width=\"40%\"}\n-   Now that we know roughly, what **data science** is, what does this discipline actually entail more concretely?\n-   In other words, what is it that a data scientist does every day?\n-   There are many ways to structure the data science, let's first look at the **seven stages** of a data science project.\n:::\n\n::: {.column .fragment width=\"60%\"}\n![](img/ds_circle.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::::\n\n## Step 1 -- Identify the problem\n\n![](img/ds_circle_1.png){fig-align=\"center\"}\n\n## Step 1 -- Identify the problem -- Key aspects\n\n::: slightlysmall\n-   **Understand the business context:**\n    -   Familiarize yourself with the industry, market trends, and internal operations.\n    -   **Example**: As a data scientist in a struggling e-commerce company, study industry benchmarks and analyze internal sales, user behavior, and engagement data.\n-   **Define the problem statement:**\n    -   Together with the business, clearly articulate what issue needs solving.\n    -   **Example**: \"Our customer churn rate has increased by 20% over the last six months, impacting revenue.\"\n-   **Identify stakeholders:**\n    -   Determine who is impacted and who can provide insights.\n    -   **Example**: *marketing* to explain and refine their existing customer engagement strategies or *customer service* to point out existing issues in post-purchase support.\n:::\n\n## Step 1 -- Identify the problem -- Key aspects\n\n::: slightlysmall\n-   **Outline goals & objectives:**\n    -   In collaboration with business, specify what success looks like and define measurable KPIs.\n    -   **Example**: \"Reduce the churn rate by 10% within the next six months.\"\n-   **Make the goals actionable:**\n    -   Identify potential strategies to achieve the goals as well as the data required to implement them.\n    -   **Example**: train a **machine learning model** to predict customer churn and use this model to tailor new customer engagement strategies. Requires data on past customer behaviour on the website and whether or not they churned.\n:::\n\n## Step 1 -- Identify the problem -- DS contributions\n\n![](img/ds_importance_business.jpg){fig-align=\"center\" width=\"85%\"}\n\n## Step 2 -- Identify available data sources\n\n![](img/ds_circle_2.png){fig-align=\"center\"}\n\n## Step 2 -- Identify available data sources\n\n-   **Definition**: A **data source** refers to the physical or digital system where data is generated, stored and managed as a data table, data object or any other storage format. It is also where, stakeholders of this data (e.g. a data scientist) can access data for further use.\n-   **Why identify data sources early?**\n    -   **Foundation for analysis:** Data sources determine the quality, scope, and reliability of your insights.\n    -   **Strategic planning:** Knowing where data comes from helps define project goals and design the analytics pipeline.\n    -   **Integration & innovation:** Combining diverse sources (internal and external) can reveal hidden trends and create competitive advantages.\n\n## Classifying data sources\n\n::::: columns\n::: {.slightlysmall .column width=\"50%\"}\n**Internal sources**\n\n-   **Definition:** Data generated, stored, and maintained within the organization.\n-   **Examples:**\n    -   Enterprise systems (CRM, ERP)\n    -   In-house databases\n    -   Spreadsheets, documents, ...\n-   **Key point:** Proprietary data that reflects your organization’s operations.\n:::\n\n::: {.slightlysmall .column width=\"50%\"}\n**External sources**\n\n-   **Definition:** Data sourced from outside the organization.\n-   **Examples:**\n    -   Public datasets (government statistics, market research)\n    -   APIs (social media, financial data feeds)\n-   **Key point:** Supplement internal data and provide broader market or industry insights.\n:::\n:::::\n\n## Internal data sources -- CRM system\n\nA Customer Relationship Management (CRM) system helps manage **customer data**. It helps businesses keep customer contact details up to date, track every customer interaction, and manage customer accounts.\n\n![](img/crm.png){fig-align=\"center\"}\n\n## Internal data sources -- ERP system\n\nThe CRM typically forms part of the Enterprise Resource Planning (ERP) system. This type of software integrates data about **all main business processes** in a single system.\n\n![](img/erp.png){fig-align=\"center\"}\n\n<!-- Note: MRP = Material Requirements Planning -->\n\n## Internal data sources -- Databases\n\n::::: columns\n::: {.slightlysmall .column width=\"60%\"}\n-   A **database** is an organized collection of data stored and accessed electronically.\n-   Databases are managed using specialized software called a **Database Management System (DBMS)**, which allows users to store, retrieve, and manipulate data efficiently.\n-   Databases are the backbone of modern applications, supporting businesses, organizations, and systems across industries.\n-   Different types of databases can be classified in terms of their structure, usage, or storage methods. **Two main types** are:\n    -   Relational / SQL\n    -   NoSQL\n:::\n\n::: {.column width=\"40%\"}\n![](img/db.png){.absolute top=\"200\" left=\"810\" width=\"42.5%\"}\n:::\n:::::\n\n## Internal data sources -- Relational databases\n\nA **relational database** organizes data into **tables** with certain pre-defined relationships to each other. These relationships are logical connections, established on the basis of interaction among these tables.\n\n![](img/rel_db.jpg){fig-align=\"center\"}\n\n## Internal data sources -- Relational databases\n\nThe **relational model** underlying such databases uses special lingo to refer to the entities that make up its structure:\n\n::::: columns\n::: {.column width=\"50%\"}\n| Familiar term | Relational DB term |\n|---------------|--------------------|\n| Table         | Relation           |\n| Row           | Tuple              |\n| Column        | Attribute          |\n:::\n\n::: {.column width=\"50%\"}\n![](img/rel_db2.svg){fig-align=\"center\"}\n:::\n:::::\n\n::: incremental\n-   Unlike tables, relations are **unordered**, i.e. you can shuffle the order of rows or columns and still get the same relation.\n-   Attributes (columns) specify a **data type** (e.g. integer or text), and each tuple (or row) contains the value of that specific data type.\n:::\n\n## Internal data sources -- Relational databases\n\n-   All tables in a relational database have an attribute known as the **primary key**, which is a unique identifier of a row.\n-   Each row can be used to create a **relationship** between different tables using a **foreign key**, i.e. a reference to a primary key of another existing table.\n\n. . .\n\nLet's see how this looks in practice: Suppose we have the following table:\n\n::: small\n| book_id | Title           | Author         | Format    | Publisher    | Country | Price |\n|---------|-----------------|----------------|-----------|--------------|---------|-------|\n| 1       | Harry Potter    | J.K. Rowling   | Paperback | Banana Press | UK      | \\$20  |\n| 2       | Harry Potter    | J.K. Rowling   | E-book    | Banana Press | UK      | \\$10  |\n| 3       | Sherlock Holmes | Conan Doyle    | Paperback | Guava Press  | US      | \\$30  |\n| 4       | The Hobbit      | J.R.R. Tolkien | Paperback | Banana Press | UK      | \\$30  |\n| 5       | Sherlock Holmes | Conan Doyle    | Paperback | Guava Press  | US      | \\$15  |\n:::\n\n. . .\n\nClearly, the primary key in this table is **book_id**.\n\n## Internal data sources -- Relational databases\n\n::: incremental\n-   What if \"Banana Press\" changed its name to \"Pineapple Press\"?\n-   We would have to change every single instance of \"Banana Press\" in the **Publisher** attribute. Very cumbersome...\n-   What if we instead organized our database like this?\n:::\n\n. . .\n\n::: small\n| book_id | Title           | Author         | Format    | Publisher_ID | Price |\n|---------|-----------------|----------------|-----------|--------------|-------|\n| 1       | Harry Potter    | J.K. Rowling   | Paperback | pub_1        | \\$20  |\n| 2       | Harry Potter    | J.K. Rowling   | E-book    | pub_1        | \\$10  |\n| 3       | Sherlock Holmes | Conan Doyle    | Paperback | pub_2        | \\$30  |\n| 4       | The Hobbit      | J.R.R. Tolkien | Paperback | pub_1        | \\$30  |\n| 5       | Sherlock Holmes | Conan Doyle    | Paperback | pub_2        | \\$15  |\n\n| Publisher_ID | Publisher    | Country |\n|--------------|--------------|---------|\n| pub_1        | Banana Press | UK      |\n| pub_2        | Guava Press  | US      |\n:::\n\n## Internal data sources -- Relational databases\n\n-   We introduced the **foreign key** \"Publisher_ID\" into book relation.\n-   Now, we would just have to change the name of the publisher once, namely in the publisher relation.\n-   This is an example of a process called [**database normalization**](https://en.wikipedia.org/wiki/Database_normalization), which helps reduce redundancy and improve data integrity.\n-   To retrieve data from a relational database, one uses a specialized computer language called **Structured Query Language (SQL)**, which gives relational databases an alternative name.\n-   To reconstruct our original book relation, the SQL statement would be:\n\n\n\n::: {.cell}\n\n```{.sql .cell-code}\nSELECT b.book_id, b.Title, b.Author, b.Format,\n       p.Publisher, p.Country, b.Price\nFROM Books AS b\nLEFT JOIN Publishers AS p ON b.Publisher_ID = p.Publisher_ID\n```\n:::\n\n\n\n## Internal data sources -- Relational databases\n\nSQL will not be part of this course, but data scientists working in industry tend to write a lot of SQL...\n\n![](img/sql_meme.jpg){fig-align=\"center\"}\n\n## Internal data sources -- Types of data\n\n-   Relational databases are the de-facto standard for managing **structured data**, i.e. data that is highly organized in a table-like format.\n-   Data can also take other forms though:\n    -   **Unstructured data** is not organized in a specific way and does therefore not lend itself to the relational model.\n    -   **Examples**: text documents, images and video.\n    -   **Semi-structured data** is a hybrid of the two preceding forms, containing some organizational elements (like tags or markers), but allowing for more flexibility than data stored in a relational model.\n    -   **Examples**: Data stored in JSON, XML or HTML files.\n\n## Internal data sources -- Types of data\n\nFor unstructured and semi-structured data, the relational model is typically not suitable, or at least suboptimal. For this purpose, **non-relational models** are preferred.\n\n![](img/types_of_data.png){fig-align=\"center\"}\n\n## Internal data sources -- NoSQL databases\n\n-   Despite some fuzzy terminology, non-relational databases are commonly referred to as **NoSQL**.\n-   Types of NoSQL databases include:\n    -   **Key-value store**: simplest form of a NoSQL database, typically of little use in data science.\n    -   **Wide column store**: uses tables, rows and columns similar to relational DBs, but names and format of columns can vary from row to row.\n    -   **Document store**: perfect for semi-structured data, can handle complex data structures.\n    -   **Graph database** prioritize relationships between data objects. They use nodes (data entities) and edges (relationships) to model data.\n-   As an illustration of the kind of benefits achievable through NoSQL databases, we consider an example for a document store.\n\n## Internal data sources -- NoSQL databases\n\n![](img/nosql_types.png){fig-align=\"center\"}\n\n## Internal data sources -- NoSQL databases\n\n-   As the name suggests, a **document store** is centred around the concept of \"document\", like a JSON or XML file.\n-   All documents are assumed to be encoded in the same format.\n-   Each document has a unique key that can be used to retrieve it.\n-   A collection of documents could be considered analogous to a **table** in a relational database, where each row is a document. However, a collection of documents is much more **flexible**:\n    -   In a table, all rows must have the same sequence of columns.\n    -   In a collection of documents however, each document can have completely different fields.\n\n## Internal data sources -- NoSQL databases\n\n::: {layout-ncol=3}\n\n![Document 1 -- Harry Potter](img/hp_json.png){fig-align=\"center\"}\n\n![Document 2 -- Sherlock Holmes](img/sh_json.png){fig-align=\"center\"}\n\n![Document 3 -- The Hobbit](img/th_json.png){fig-align=\"center\"}\n\n:::\n\nAdvantages of such a NoSQL database:\n\n-   No need to normalize\n-   Easier extensibility: changes in one document do not affect others.\n-   Better locality (all information on a document in one place instead of spread across several tables).\n\n## Internal data sources -- Others\n\n-   Unfortunately, a lot of data in corporations is *not* in a nicely structured form in a database... Instead, big amounts of data are spread around in **messy spread sheets**, e-mails, presentations, csv-files, etc.\n-   Organizing and cleaning such data to gain meaningful insight is a key part of being a data scientist.\n\n![](img/dirty_excel.png){fig-align=\"center\"}\n\n\n## External data sources -- Public data sets\n\n-   External data sources are often crucial to understand the general economic environment, market or industry trends, and much more.\n-   The first approach towards external data sources is usually to verify whether there are any **publicly available** data sets from reliable sources, such as:\n\n::: {layout-ncol=3}\n\n![](img/statistik_austria.png){fig-align=\"center\"}\n\n![](img/destatis.svg){fig-align=\"center\"}\n\n![](img/usdata.png){fig-align=\"center\"}\n\n![](img/wb.png){fig-align=\"center\"}\n\n![](img/nber.png){fig-align=\"center\"}\n\n![](img/statista.png){fig-align=\"center\"}\n\n:::\n\n## External data sources -- APIs\n\n-   Often, rather than downloading a data set in form of a csv or xls file, data providers offer **Application Programming Interfaces (APIs)** to access their data directly.\n-   APIs serve as a bridge between different software applications, enabling them to communicate and share data in (near) real-time.\n-   As a data source, APIs can be used, for instance, to access data from...\n    -   ... social media to detect and leverage current viral trends.\n    -   ... AI-providers like OpenAI to incorporate information produced by ChatGPT.\n    -   ... tech companies like Google to identify highly-rated competitors in the area based on Google Maps.\n    -   ...\n\n## External data sources -- APIs\n\n::: slightlysmall\nLet's say you wanted to find out, how many views all of your company's tweets on X generated last week. If your company tweets a lot, that's a lot of manual labour... Instead, we could write a program (in R) that uses the [X API](https://docs.x.com/x-api/introduction) to gather this information.\n:::\n\n![](img/api.png){fig-align=\"center\"}\n\n## External data sources -- APIs\n\n::: slightlysmall\n-   Communication with APIs works through a **request and response** cycle: the request is sent to the API, which retrieves the data and returns it to the user in form of the response.\n-   An API request will typically include the following components:\n    -   **Endpoint**: a dedicated URL declared by the API provider to access the desired resource, e.g. https://api.x.com/2/insights/historical (see [here](https://docs.x.com/x-api/posts/get-historical-metrics-for-posts)).\n    -   **Method**: the type of operation the client wants to perform. Data retrieval operations typically use the **GET method** (see [here](https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/HTTP-methods) for more information on HTTP methods).\n    -   **Parameters**: the variables indicating the specific instructions for the API to process, e.g. the time period for which you want to analyze the views of all tweets.\n    -   **Request headers**: meta information about the request, e.g. authentication credentials, such as an **API key**.\n    -   **Request body**: contains further information to be passed to the API, e.g. parameters that are not passed as part of the endpoint.\n:::\n\n## External data sources -- APIs\n\n![](img/http_get.jpg){fig-align=\"center\"}\n\n## External data sources -- APIs\n\n-   The **response** returned by the API will then typically include the following components:\n    -   **Status code**: HTTP status codes are three-digit codes that indicate the outcome of an API request. Some common ones are:\n        -   200: OK (server successfully returned the requested data)\n        -   400: Bad request (e.g. malformatted request syntax)\n        -   404: Not found (server cannot find requested resource)\n    -   **Response headers**: very similar to request headers, but provide additional information about response.\n    -   **Response body**: includes actual requested data, e.g. the number of views for each of last week's tweets.\n\n## External data sources -- APIs\n\n![](img/http_response.jpg){fig-align=\"center\"}\n\n## Step 3 -- Identify if additional sources are needed\n\n![](img/ds_circle_3.png){fig-align=\"center\"}\n\n## Step 4 -- Statistical analysis\n\n![](img/ds_circle_4.png){fig-align=\"center\"}\n\n## Step 4 -- Statistical analysis\n\n-   After data has been obtained, the data scientist needs to clean, process and explore it. This can involve:\n    -   Handling missing values, outliers, and noise.\n    -   **Exploratory data analysis (EDA)**: Visualizations, correlation analysis, and summary statistics.\n-   Based on clean data, **statistical tests** can be employed to validate existing business hypotheses. Here, all the tests you have (hopefully) learned in your statistics classes come in, e.g. T-tests, ANOVA, $\\chi^2$ tests, etc.\n-   Through this process, the data scientist can start to develop an **understanding** of the data.\n\n## Step 5 -- Implementation and development\n\n![](img/ds_circle_5.png){fig-align=\"center\"}\n\n## Step 5 -- Implementation and development\n\n-   After familiarizing themselves with the data, data scientists then have to **translate insights into action**. This involves offering some kind of product back to the business.\n-   This could take the form of:\n    -   Training and deploying a **machine learning model**, e.g. offering the business a model that tells them the probability that a given customer will churn.\n    -   Building **dashboards** to make the data-driven insights accessible to non-technical people in business.\n    -   Support strategic decision making by providing appropriate statistics, figures, graphs and other data.\n\n## Step 5 -- Implementation and development\n\n![](img/dashboard.png){fig-align=\"center\"}\n\n## Step 6 -- Communicate results\n\n![](img/ds_circle_6.png){fig-align=\"center\"}\n\n## Step 6 -- Communicate results\n\n-   Communication is an often underappreciated aspect of data science in business: any data insight can only be as good as it can be made understood by the people that (should) act on it.\n-   Key communication goals:\n    -   **Simplify** complex technical details without losing accuracy.\n    -   **Tailor the message to your audience** (executives, technical teams, clients).\n-   Communication strategies:\n    -   **Visual storytelling**: Use charts, graphs, and dashboards to highlight trends and key metrics.\n    -   **Narrative & context**: Frame results within a business story: What problem was solved? How do the results impact the business?\n    -   **Actionable insights**: Include clear recommendations and next steps.\n\n## Step 7 -- Maintenance\n\n![](img/ds_circle_7.png){fig-align=\"center\"}\n\n## Step 7 -- Maintenance\n\n-   Once a **data science product** like a machine learning model or a dashboard is \"in production\", i.e. is used by business, it will not age like fine wine...\n-   Instead, changes in data over time and general [software rot](https://en.wikipedia.org/wiki/Software_rot) will quickly cause the product to be useless if left unchanged.\n-   Hence, data scientists need to subject their products to continuous **maintenance**:\n    -   **Monitor performance over time**: track metrics to detect data drift or deterioration in model performance.\n    -   **Update models and systems**: retrain models with new data when necessary.\n    -   Regularly engage stakeholders for **feedback**\n    -   Identify new problems and areas for improvement and **restart** the cycle.\n\n## The essence of Data Science\n\n::::: columns\n::: {.slightlysmall .column width=\"45%\"}\n-   Data science is a demanding field that requires skills in maths, statistics and computer science, but also high levels of **domain expertise** and **excellent communication**.\n-   Thus, it is impossible to cover all areas of DS in a single course...\n-   This course focuses on what could be called the **essence of data science**:\n    -   Statistical analysis\n    -   Implementation and development\n    -   Communication of results\n-   We will further break these steps down in the **data science workflow**.\n:::\n\n::: {.column width=\"55%\"}\n![](img/ds_circle_8.png){fig-align=\"center\" width=\"100%\"}\n:::\n:::::\n\n# The Data Science workflow\n\n## The Data Science workflow\n\n![](img/data-science-cycle.001.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Part I\n\n![](img/data-science-cycle.002.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Part I\n\n![](img/data-science-cycle.003.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Part II\n\n![](img/data-science-cycle.004.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Part III\n\n![](img/data-science-cycle.005.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Understanding data\n\n![](img/data-science-cycle.006.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- Part IV\n\n![](img/data-science-cycle.007.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## The Data Science workflow -- How? Program!\n\n![](img/data-science-cycle.009.png){fig-align=\"center\"}\n\n::: xxsmall\nSource: [Wickham et al. (2023)](https://r4ds.hadley.nz/)\n:::\n\n## How about Data Analytics?\n\n-   The name of the course is **Data Science and Data Analytics**, but only data science has been mentioned so far. How about data analytics?\n-   Essentially, **data analytics** is data science without the strong computer science and machine learning focus. Therefore, the steps involved in data analytics are typically a subset of the steps in a data science project:\n\n![](img/ds_vs_da.jpg){fig-align=\"center\"}\n\n## How about Data Analytics?\n\nThe two fields thus have a **large intersection**, which is also reflected in the tasks that data scientists and data analysts share:\n\n![](img/ds_vs_da2.png){fig-align=\"center\" width=\"50%\"}\n\nAs we are focused on tasks in the intersection, we will mostly be referring to **data science** as the overarching topic in the remainder of this course.\n",
    "supporting": [
      "01_Introduction_to_DS_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}